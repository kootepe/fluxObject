[defaults]
# set ini as active or inactive
active = 0
# mode defines how to the script will be ran
mode = man
# set to 1 to create excel summaries, this hogs quite a bit of RAM
create_excel = 0
# path in the container where to place created excels, no need to change this
excel_directory = ./excel_dir
# Useful if you have .env file used with docker and want to use those
# paths to run the script without docker
use_dotenv = 0
# limit the amount of data to process on one run of the script, in days
limit_data = 14
# default pressure for flux calculation if no file supplied
default_temperature = 10.0
# default pressure for flux calculation if no file supplied
default_pressure = 1000.0
# 1 to get temp and pressure from file, 0 to use defaults
get_temp_and_pressure_from_file = 1
# file that defines the cycle of the chambers
chamber_cycle_file = 
# how many seconds between each file
file_timestep = 
# date to use if there's no data in the database
season_start = 

[measuring_chamber]
# in mm
chamber_height = 500
chamber_width = 1000
chamber_length = 1000

[chamber_start_stop]
# the length of the cycle for a single chamber
end_of_cycle = 
# how many seconds into the cycle to start the gas measurement
start_of_measurement = 
# how many seconds into the cycle to end the measurement
end_of_measurement = 

[manual_measurement_time_data]
# the other parameters for measurement files like columns and names are
# currently hardcoded
scan_or_generate = 1
# path to the file(s) you are reading
path = 
file_timestamp_format = %%y%%m%%d
file_extension = .txt

# gas measurement
[measurement_data]
scan_or_generate = 1
# path to the file(s) you are reading
path = 
# how many rows to skips in the csv file
skiprows = 
# the format of the timestamp in the .csv file
file_timestamp_format = 
# file extension of the file to read
file_extension = 
# .csv delimiter
delimiter = \t
# names of the columns that will be read
names=
# which columns to read from the csv file, numbers separated by commas eg.
# columns = 1,2,3,4
columns=
# old licor files are missing diagnostic column
columns_alternative = 
# data types of the columns that will be read, comma separated. eg,
# dtypes = str,str,int,float
dtypes = 

# air pressure measurement
[air_pressure_data]
# 1 = scan, 0 = generate 
scan_or_generate = 1
# path to the file(s) you are reading
path = 
# the format of the timestamp in the .csv file
file_timestamp_format = 
# .csv delimiter
delimiter = 
# how many rows to skips in the csv file
skiprows = 
# number of the column to read in the .csv, start at 0
timestamp_column = 
timestamp_column_name = datetime 
timestamp_column_dtype = str
# the format of the timestamp in the .csv file
timestamp_format = 
# number of the column to read in the .csv, start at 0
measurement_column = 
measurement_column_name = air_pressure
measurement_column_dtype = float

# air temperature measurement
[air_temperature_data]
# 1 = scan, 0 = generate 
scan_or_generate = 1
# path to the file(s) you are reading
path = 
# the format of the timestamp in the .csv file
file_timestamp_format = 
# .csv delimiter
delimiter = 
# how many rows to skips in the csv file
skiprows = 
# number of the column to read in the .csv, start at 0
timestamp_column = 
timestamp_column_name = datetime 
timestamp_column_dtype = str
# the format of the timestamp in the .csv file
timestamp_format = 
# number of the column to read in the .csv, start at 0
measurement_column = 
measurement_column_name = air_temperature_c
measurement_column_dtype = float

[influxDB]
# URL of your Influxdb instance
url = 
# read/write token for the bucket you are pusing data to
token = 
# name of the bucket where to push the data
bucket = 
# name of the organization where the bucket is located
organization = 
# name of the measurement in the bucket
measurement_name = 
# timeout value for influxdb
timeout = 10000
# timezone of the data, needs to be in specific format
timezone = 
# which column to use for tagging the data
tag_columns = chamber
# format of the infludb timestamp
influxdb_timestamp_format = %%Y-%%m-%%d %%H:%%M:%%S
